# Truly Unbiased

## Motivation

Large language models have achieved remarkable capabilities, but a major limitation is their tendency to exhibit harmful biases across different attributes like gender, race, age, and others. These biases originate from the training data which often reflects societal biases and imbalances. Current de-biasing approaches like data augmentation, filtering, and token replacement are limited in their ability to fundamentally rewrite the underlying data distributions.

Imagine if we are raising our LLM in a carefully curated, bias-free environment.

The goal of this project is to generate truly unbiased large language models by fine-tuning them on carefully de-biased datasets that simulate an equitable world across attributes like gender and race. 
